# Gravitee Kubernetes Operator - Integration Tests 101

This document provides all the information you need regarding the operator integration tests, from getting started to the convention we use when writing tests. 

## The stack

Test are written and run using the [gingko](https://onsi.github.io/ginkgo/) testing framework, paired with the [gomega](https://onsi.github.io/gomega/) matcher library against a local kind cluster.

This section does not describe how to use gingko or gomega. Please read the respective documentations linked above before going further.

> Note: kubectl, helm and kind are assumed to have been installed on your machine.

## Install tooling

Installing tooling can be achieved by running the `install-tools` target

```sh
make install-tools
```

Binaries are installed in a `bin/` folder located at the root of this repository.

Tools of interest when it comes to writing integration tests are:

  - the ginkgo cli to run the tests
  - controller-gen if runtime code has been modified to generate the CRD manifests

## Integration cluster config and test filters

As said before, tests are run against a kind cluster where APIM as been previously deployed in order to perform assertion against the resulting state of applying various resources.

As of this writing, the cluster can be started with two APIM setups

  - the default mode runs the whole APIM stack except for elasticsearch and the portal
  - the dbless mode just runs a gateway

Because tests involving a management context would obviously break when running in dbless mode, filters are put in place in order to segregate tests running without a context, which can pass with both setups, and tests running with a context, which require running the default mode.

This filters are
  - withContext (only passing with the default mode)
  - withoutContext (passing with both modes)
  
Running the cluster with one mode or the other and applying filters is described in the next sections.

## Running the integration cluster

The `start-cluster` make target allows you to start a local kind cluster in order to run the tests. Configuring the way APIM is deployed can be achieved using the following environment variables.

| Name | Description | Default value |
|---|---|---|
| APIM_VALUES | The value file to use when deploying APIM to the cluster using Helm. (defaults to deploying all components) | `values.yaml` |
| APIM_IMAGE_REGISTRY | The docker registry to pull APIM images from. Useful if you want to work against images under development, which  are published in a private registry (defaults to docker hub public image registry) | `graviteeio` |
| APIM_IMAGE_TAG | The docker tag used to pull APIM images. Useful if you want to run test against a support version (defaults to the latest published APIM release) | `latest` |

### Examples

Running the command without any argument will pull the latest APIM image tag from docker hub and launch all components

```sh
make start-cluster
```

Running with the latest image under development (requires access to our private registry)

```sh
# Gain access to the registry
az acr login -n graviteeio

# Start using latest development images
APIM_IMAGE_REGISTRY=graviteeio.azurecr.io APIM_IMAGE_TAG=master-latest make start-cluster 
```

Running with the latest image under development and dbless mode

```sh
APIM_VALUES="values-dbless.yaml" APIM_IMAGE_REGISTRY=graviteeio.azurecr.io APIM_IMAGE_TAG=master-latest make start-cluster
```

## Deploying Custom Resource Definitions to the cluster

Before running the test, your local cluster needs to be aware of resources handled 
by the operator. This means applying the CRD folder to the cluster and can be achieved using the following make target

```sh
make install
```

If you are touching the code while writing your test, make sure you run the following targets before installing the CRDs to ensure autogenerated code and CRDs are up to date

```sh
make generate manifests
```

## Running the tests

Tests are divided into several packages/suites, one for each controller

```
test
‚îú‚îÄ‚îÄ integration
    ‚îú‚îÄ‚îÄ apidefinition
    ‚îú‚îÄ‚îÄ apiresource
    ‚îú‚îÄ‚îÄ application
    ‚îú‚îÄ‚îÄ ingress
    ‚îú‚îÄ‚îÄ managementcontext
    ‚îî‚îÄ‚îÄ secret
```

### Examples

Running all integration tests at once

```
./bin/gingko ./test/integration/...
```

Running all integration tests not involving a management context (required if you run APIM in dbless mode)

```
./bin/ginkgo --label-filter="withoutContext" ./test/integration/...
```

Running all integration test involving a management context

```
./bin/ginkgo --label-filter="withContext" ./test/integration/...
```


Running only apidefinition tests involving a management context

```
./bin/ginkgo --label-filter="withContext" ./test/integration/apidefinition/...
```

## Conventions & good practices we use when writing tests

### Use one file per test

Making async assertions against the cluster makes the code verbose so let's 
not bloat files and stick to this convention üôè

### Stick to the naming convention

Tests running without a context should be named as follows

```
create_withoutContext_test.go
```

Tests running with a context should be named as follows

```
create_withContext_test.go
```

Add additional context if your test if more specific that a simple create|update|delete

```
create_withContext_andLocalFalse_test.go
```

### Gomega conventions

Don't use boolean assertions except when you are testing against a flag. This results in meaningless feedbacks when the test fails.

```golang
// Don't use this
Eventually(func() error {
    // some code returning error
    return err == nil
}, timeout, interval).Should(BeTrue()) 

// Use this instead
Eventually(func() error {
    // some code returning error
    return err
}, timeout, interval).Should(Succeed()) 
```

Do **NOT** use `Expect()` in async assertions. This breaks the behavior of Gomega async matchers. Return an error instead.

```golang

// Don't use this
Eventually(func() error {
    // some code returning error
    Expect(err).ToNot(HaveOccurred())
    return nil
}, timeout, interval).To(Succeed())

// Use this instead
Eventually(func() error {
    // some code returning error
    return err
}, timeout, interval).To(Succeed())
```

Prefer `To(Succeed())` over `ToNot(HaveOcurred())` except when the asserted value is `err`

```golang
// Don't use this
Expect(manager.Client()).delete(ctx, api).ToNot(HaveOcurred())

// Use this instead
Expect(manager.Client()).delete(ctx, api).To(Succeed())

// Don't use this
Expect(err).To(Succeed())

// Use this instead
Expect(err).To(NotHaveOccurred())
```

Use `Should` for async assertion only

```golang
// Don't use this
Expect(err).Should(NotHaveOccurred())

// Use this instead
Expect(err).To(NotHaveOccurred())

// Don't use this
Eventually(func() error {}, timeout, interval).To(Succeed())

// Use this instead
Eventually(func() error {}, timeout, interval).Should(Succeed())
```

Write readable `By` statements

This statements end up assembled to build an actual sentence in the tests report.
Please mind the language you use while righting them. Also, don't use capital letter when beginning the statement.

```golang
// Don't use this
By("Check that no error")

// Use this instead
By("applying the resource and expecting no error to happen")
```

## Writing a simple test suite

### Bootstrapping the test suite

If you are starting a whole new package, you need to setup a `suite_test.go` file as follow

```
test
‚îú‚îÄ‚îÄ integration
    ‚îú‚îÄ‚îÄ apidefinition
        ‚îú‚îÄ‚îÄ suite_test.go
```

Here is a minimal version of that file

```golang
package apidefinition

import (
	"testing"
	"time"

	"github.com/onsi/gomega/gexec"

	. "github.com/onsi/ginkgo/v2"
	. "github.com/onsi/gomega"
)

// This is required for the suite to run
func TestResources(t *testing.T) {
	RegisterFailHandler(Fail)
	RunSpecs(t, "API Definition Suite")
}

var _ = SynchronizedBeforeSuite(func() {
	// If we run the tests in parallel, this function is executed 
    // before executing parallel nodes
}, func() {
	// Executed before each parallel node
})


var _ = SynchronizedAfterSuite(func() {
    // If we run the tests in parallel, this function is executed 
    // after all parallel nodes have been executed

    // This kills the operator process spawned during test initialization
	gexec.KillAndWait(5 * time.Second)
}, func() {
    // Executed after each parallel node
})
```

### Adding a test file

Labels are exposed into a `labels` sub package located in the test `internal/integration` package

```golang
// First parameter should be the operation under test
// Second parameter is the label that will allow applying filters when running your test
var _ = Describe("Create", labels.WithoutContext, func() {
	It("should create an API Definition", func() {
        // This will initialize required resources from the examples directory
        // and apply them on the cluster.
		fixtures := fixture.Builder().
			WithAPI(constants.Api).
			Build().
			Apply()


        By("calling gateway endpoint, expecting status 200")
        
        httpClient := http.Client{Timeout: 5 * time.Second}
		endpoint := constants.BuildAPIEndpoint(fixtures.API)

		Eventually(func() error {
			res, err := httpClient.Get(endpoint)
			return assert.NoErrorAndHTTPStatus(err, res, http.StatusOK)
		}, constants.EventualTimeout, constants.Interval).Should(Succeed())

	})
})
```

üí° After writing your test and before committing it, don't forget to run linters using the `make lint-fix` target

```sh
make lint-fix
```

